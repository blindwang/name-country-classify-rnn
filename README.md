# makenames
**ä¸åŒå›½å®¶å§“æ°æ–‡æœ¬ç”Ÿæˆï¼ˆPytorchå®Œæˆï¼‰**
1. ç½‘ç»œç»“æ„ï¼š
è‡ªå®šä¹‰RNNç½‘ç»œç»“æ„ã€GRUã€LSTMç­‰ä¸åŒç½‘ç»œçš„å°è¯•
2. ä¼˜åŒ–æ–¹æ³•ï¼š
ä¸åŒä¼˜åŒ–æ–¹æ³•ï¼ŒAdamã€AdamWç­‰ä¼˜åŒ–æ–¹æ³•çš„å°è¯•ï¼Œå°½é‡å¯¹æ¯”ä¸åŒä¼˜åŒ–æ–¹æ³•çš„ç»“æœ
3. æ¯”è¾ƒä¸åŒbatch_sizeçš„è®­ç»ƒç»“æœåŠæ•ˆç‡

**æ•°æ®é›†**

ä½¿ç”¨18ä¸ªå›½å®¶å§“æ°çš„æ–‡æœ¬txt,åœ¨æ­¤åŸºç¡€ä¸Šè‡ªè¡Œæ‰©å……æ•°æ®é›†å†…å®¹ï¼Œå°½é‡æ¯ä¸ªå›½å®¶åŒ…å«50ä¸ªä»¥ä¸Šä¸åŒå§“æ°

## æ•°æ®å¤„ç†

### æ•°æ®é¢„å¤„ç†

ä»[è¿™é‡Œ](https://download.pytorch.org/tutorial/data.zip)ä¸‹è½½æ•°æ®ï¼Œå¹¶å°†å…¶æå–åˆ°å½“å‰ç›®å½•ã€‚

åœ¨data/namesç›®å½•ä¸­åŒ…æ‹¬äº†18ä¸ªåä¸º[Language].txtçš„æ–‡æœ¬æ–‡ä»¶ã€‚æ¯ä¸ªæ–‡ä»¶åŒ…å«å¾ˆå¤šåå­—ï¼Œæ¯è¡Œä¸€ä¸ªåå­—ï¼Œå¤§éƒ¨åˆ†æ˜¯ç½—é©¬åŒ–çš„ï¼ˆä½†ä»ç„¶éœ€è¦ä»Unicodeè½¬æ¢ä¸ºASCIIï¼‰ã€‚

æœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ªæ¯ä¸ªè¯­è¨€çš„åå­—åˆ—è¡¨çš„å­—å…¸ï¼Œ{language: [names...]}ã€‚

```python
from __future__ import unicode_literals, print_function, division
from io import open
import glob
import os

def findFiles(path): return glob.glob(path)

print(findFiles('data/names/*.txt'))

import unicodedata
import string

all_letters = string.ascii_letters + " .,;'"
n_letters = len(all_letters)

# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427
def unicodeToAscii(s):
    return ''.join(
        c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn'
        and c in all_letters
    )

print(unicodeToAscii('ÅšlusÃ rski'))

# Build the category_lines dictionary, a list of names per language
category_lines = {}
all_categories = []

# Read a file and split into lines
def readLines(filename):
    lines = open(filename, encoding='utf-8').read().strip().split('\n')
    return [unicodeToAscii(line) for line in lines]

for filename in findFiles('data/names/*.txt'):
    category = os.path.splitext(os.path.basename(filename))[0]
    all_categories.append(category)
    lines = readLines(filename)
    category_lines[category] = lines

n_categories = len(all_categories)
```

### æ„å»ºdataloader

`NameDataset`ç±»ç”¨äºåŠ è½½æ•°æ®é›†ï¼Œ`build_dataloader`å‡½æ•°ç”¨äºæ„å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„DataLoaderå¯¹è±¡ã€‚

åœ¨NameDatasetç±»ä¸­ï¼Œé¦–å…ˆè·å–æ‰€æœ‰æ•°æ®æ–‡ä»¶çš„æ–‡ä»¶åï¼Œç„¶åå°†æ¯ä¸ªæ–‡ä»¶åä¸­çš„ç±»åˆ«ä½œä¸ºä¸€ä¸ªç±»åˆ«æ ‡ç­¾ï¼Œå°†æ–‡ä»¶ä¸­çš„æ¯ä¸€è¡Œä½œä¸ºä¸€ä¸ªæ ·æœ¬ï¼Œå°†ç±»åˆ«æ ‡ç­¾å’Œæ•°æ®ç»„æˆä¸€ä¸ªå…ƒç»„å¹¶æ·»åŠ åˆ°`lines`åˆ—è¡¨ä¸­ã€‚

é€šè¿‡ä¼ å…¥çš„idxå‚æ•°è·å–å¯¹åº”çš„æ•°æ®å’Œæ ‡ç­¾ï¼Œå°†è¾“å…¥æ•°æ®è½¬æ¢æˆTensorå¯¹è±¡ï¼Œå°†æ ‡ç­¾è½¬æ¢æˆLongTensorå¯¹è±¡ï¼Œå¹¶è¿”å›ä¸€ä¸ªå…ƒç»„ã€‚

æœ€åç”¨`torch.utils.data.DataLoader`ç›´æ¥åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„DataLoaderå¯¹è±¡ã€‚

```python
import torch
from data import *
import random


def collate(batch):
    inputs = [item[0] for item in batch]
    targets = [item[1] for item in batch]
    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True)
    targets = torch.stack(targets)
    return inputs, targets


class NameDataset(torch.utils.data.Dataset):
    def __init__(self, root_dir, is_train=True):
        self.categories = []
        self.lines = []
        self.n_categories = 0

        for filename in findFiles(root_dir + '/*.txt'):
            category = filename.split('/')[-1].split('.')[0]
            self.categories.append(category)
            lines = readLines(filename)

            if is_train:
                lines = lines[:int(0.8 * len(lines))]
            else:
                lines = lines[int(0.8 * len(lines)):]

            self.lines += [(line, self.n_categories) for line in lines]
            self.n_categories += 1

    def __len__(self):
        return len(self.lines)

    def __getitem__(self, idx):
        line, category_idx = self.lines[idx]
        category = torch.tensor(category_idx, dtype=torch.long)
        line_tensor = lineToTensor(line)
        return line_tensor, category


def build_dataloader(batch_size):
    train_dataset = NameDataset('data/names/', is_train=True)
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate)
    test_dataset = NameDataset('data/names/', is_train=False)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate)
    return train_loader, test_loader, train_dataset, test_loader
```

## åˆ›å»ºæ¨¡å‹

æ„å»ºåŸºäºå¾ªç¯ç¥ç»ç½‘ç»œçš„ä¸åŒç½‘ç»œæ¶æ„ï¼ŒRNNã€Bidirectional-RNNã€GRUã€Bidirectional-GRUã€Bidirectional-LSTMã€‚

### RNN
ä¸€æ¡è®­ç»ƒæ•°æ®å°±æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²+ä¸€ä¸ªæ ‡æ³¨ï¼Œå­—ç¬¦ä¸²åœ¨æ•°æ®é¢„å¤„ç†éƒ¨åˆ†å·²ç»è½¬å˜ä¸ºASCIIç¼–ç æ ¼å¼ï¼Œåœ¨æ„å»ºdataloaderé˜¶æ®µå·²ç»å¤„ç†ä¸ºtensorï¼Œæ¯ä¸ªå­—ç¬¦éƒ½æ˜¯ä¸€ä¸ª58ç»´çš„tensorï¼ˆ58æ˜¯æ‰€æœ‰å­—ç¬¦ä¸ªæ•°çš„æ€»å’Œï¼‰ã€‚å¹¶ä¸”è€ƒè™‘åˆ°å­—ç¬¦ä¸²ä¸ç­‰é•¿çš„æƒ…å†µï¼Œå·²ç»å°†å…¶è¿›è¡Œäº†padå¡«å……ã€‚

å¾ªç¯ç¥ç»ç½‘ç»œçš„æ€æƒ³æ˜¯å°†æ¯ä¸ªå­—ç¬¦ï¼ˆæ¯ä¸ª58ç»´çš„tensorï¼‰ä¾æ¬¡è¾“å…¥éšè—å±‚ï¼Œå¹¶ä¸”ä¸‹ä¸€æ¬¡çš„è¾“å…¥ä¼šå°†å‰ä¸€æ¬¡çš„éšè—å±‚ä¹Ÿä½œä¸ºè¾“å…¥ã€‚

å°±å¦‚ä¸‹å›¾çš„x1..x4ï¼Œå°±æ˜¯ä»£è¡¨äº†ä¸€ä¸ªå­—ç¬¦ï¼Œh0æ˜¯ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„éšè—å±‚ã€‚

![model](pics/last_hidden_output.jpg)

ç”±äºè¯¥ä»»åŠ¡æ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œå¯¹äºæœ€ç»ˆçš„è¾“å‡ºï¼Œé‡‡ç”¨å°†æœ€åä¸€ä¸ªè¾“å‡ºåšå…¨è¿æ¥ï¼Œè¾“å‡ºåˆ†ç±»ç»“æœã€‚

è¿™æ˜¯ä¸€ä¸ªæ‰‹å†™çš„RNNæ¨¡å‹ï¼Œè¾“å…¥çš„ç»´åº¦æ˜¯[batch_size, n_seq, n_letters=58]ï¼Œä¾æ¬¡å¤„ç†æ¯ä¸ª`seq`ï¼Œå°†`hidden`å’Œ`input`åœ¨æœ€åä¸€ä¸ªç‰¹å¾ç»´åº¦è¿›è¡Œæ‹¼æ¥ï¼Œé€å…¥`i2h`çº¿æ€§å±‚ï¼Œåœ¨è¿›è¿‡`i2o`çº¿æ€§å±‚ï¼Œåˆ†åˆ«å¾—åˆ°`hidden`å‘é‡å’Œä¸€ä¸ª`output`å‘é‡ï¼Œ`hidden`å‘é‡ä¼šæˆä¸ºä¸‹ä¸€ä¸ª`seq`çš„è¾“å…¥`hidden`ï¼Œè€Œæœ€åä¸€ä¸ª`output`å‘é‡ç»è¿‡`log_softmax`å‡½æ•°å¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚

```python
import torch
import torch.nn as nn

class RNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(RNN, self).__init__()

        self.hidden_size = hidden_size

        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)
        self.i2o = nn.Linear(input_size + hidden_size, output_size)

    def forward(self, inputs):
        batch_size, seq_len, input_size = inputs.size()  # [batch_size, n_seq, n_letters]
        inputs = inputs.permute(1, 0, 2)  # è°ƒæ•´è¾“å…¥å¼ é‡çš„ç»´åº¦ä¸º[seq_len, batch_size, input_size]
        hidden = torch.zeros(batch_size, self.hidden_size, device=inputs.device)
        outputs = []
        for i in range(seq_len):
            input = inputs[i]
            combined = torch.cat((input, hidden), -1)  # [B, input+hidden]
            hidden = self.i2h(combined)
            output = self.i2o(combined)
            output = torch.log_softmax(output, dim=-1)
            # output = self.softmax(output)
            outputs.append(output)
        outputs = torch.stack(outputs, dim=1)  # å°†è¾“å‡ºå¼ é‡çš„ç»´åº¦è°ƒæ•´ä¸º[batch_size, n_seq, output_size]
        return outputs[:,-1,:]
```

å¦‚æœä½¿ç”¨pytorchè‡ªå¸¦çš„RNNæ¨¡å—ï¼Œåªéœ€è¦å¢åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚ä½œä¸ºè¾“å‡ºå³å¯ã€‚å¹¶ä¸”å¯ä»¥è®¾ç½®RNNçš„å±‚æ•°æ¥å¢åŠ ç½‘ç»œå¤æ‚åº¦ï¼Œæé«˜è®­ç»ƒæ•ˆæœã€‚ä¸ºäº†å’Œæ‰‹å†™çš„ç½‘ç»œè¿›è¡ŒåŒºåˆ†ï¼Œè¿˜å°†å…¶è®¾ä¸ºäº†**åŒå‘**å¾ªç¯ç¥ç»ç½‘ç»œã€‚

```python
import torch
import torch.nn as nn

class BiRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=2):
        super(BiRNN, self).__init__()

        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(2*hidden_size, output_size)

    def forward(self, inputs):
        outputs, h_n = self.rnn(inputs)
        outputs = self.fc(outputs[:, -1, :])
        outputs = torch.log_softmax(outputs, dim=-1)
        return outputs
```

### GRU

å¯¹äºGRUï¼Œä½¿ç”¨sigmoidå’Œtanhå‡½æ•°å¯¹è¾“å…¥å’Œéšå«çŠ¶æ€è¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°update_gateã€reset_gateå’Œnew_memoryå‘é‡ï¼Œ

![gru](pics/gru.png)

è¿™å¼ å›¾ä¸­rtå¯¹åº”reset_gateï¼Œztå¯¹åº”update_gateï¼Œè€Œht_hatå¯¹åº”new_memoryã€‚

```python
import torch
import torch.nn as nn

class GRU(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(GRU, self).__init__()

        self.hidden_size = hidden_size

        self.update_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.reset_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.new_memory = nn.Linear(input_size + hidden_size, hidden_size)
        self.output_layer = nn.Linear(hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim=-1)

    def forward(self, inputs):
        batch_size, seq_len, input_size = inputs.size()  # [batch_size, n_seq, n_letters]
        inputs = inputs.permute(1, 0, 2)  # è°ƒæ•´è¾“å…¥å¼ é‡çš„ç»´åº¦ä¸º[seq_len, batch_size, input_size]
        hidden = torch.zeros(batch_size, self.hidden_size, device=inputs.device)
        outputs = []
        for i in range(seq_len):
            input = inputs[i]
            combined = torch.cat((input, hidden), -1)
            update_gate = torch.sigmoid(self.update_gate(combined))
            reset_gate = torch.sigmoid(self.reset_gate(combined))
            new_memory = torch.tanh(self.new_memory(torch.cat((input, reset_gate * hidden), -1)))
            hidden = (1-update_gate) * hidden + update_gate * new_memory
            output = self.output_layer(hidden)
            output = self.softmax(output)
            outputs.append(output)
        outputs = torch.stack(outputs, dim=1)  # å°†è¾“å‡ºå¼ é‡çš„ç»´åº¦è°ƒæ•´ä¸º[batch_size, n_seq, output_size]
        return outputs[:, -1, :]
```

å¦‚æœä½¿ç”¨pytorchè‡ªå¸¦çš„GRUæ¨¡å—ï¼Œåªéœ€è¦å¢åŠ ä¸€ä¸ªå…¨è¿æ¥å±‚ä½œä¸ºè¾“å‡ºå³å¯ã€‚åŒæ ·å¯ä»¥è®¾ç½®GRUçš„å±‚æ•°å’Œå°†å…¶å˜ä¸ºåŒå‘å¾ªç¯ç¥ç»ç½‘ç»œæ¥å¢åŠ ç½‘ç»œå¤æ‚åº¦ï¼Œæé«˜è®­ç»ƒæ•ˆæœã€‚

```python
import torch
import torch.nn as nn

class BiGRU(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=2):
        super(BiGRU, self).__init__()

        self.gru = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(2*hidden_size, output_size)

    def forward(self, inputs):
        outputs, h_n = self.gru(inputs)
        outputs = self.fc(outputs[:, -1, :])
        outputs = torch.log_softmax(outputs, dim=-1)
        return outputs
```

### LSTM

LSTMçš„ç½‘ç»œç»“æ„åŒ…å«ä¸‰ä¸ªé—¨ï¼ˆinput gateã€forget gateå’Œoutput gateï¼‰å’Œä¸€ä¸ªè®°å¿†å•å…ƒï¼ˆmemory cellï¼‰ã€‚

![lstm](pics/lstm.jpg)

```python
import torch
import torch.nn as nn

class LSTM(nn.Module): 
    def init(self, input_size, hidden_size, output_size): 
        super(LSTM, self).init()

        self.hidden_size = hidden_size

        self.forget_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.input_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.cell_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.output_gate = nn.Linear(input_size + hidden_size, hidden_size)
        self.output_layer = nn.Linear(hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim=-1)

    def forward(self, inputs):
        batch_size, seq_len, input_size = inputs.size()  # [batch_size, n_seq, n_letters]
        inputs = inputs.permute(1, 0, 2)  # è°ƒæ•´è¾“å…¥å¼ é‡çš„ç»´åº¦ä¸º[seq_len, batch_size, input_size]
        hidden = torch.zeros(batch_size, self.hidden_size, device=inputs.device)
        cell = torch.zeros(batch_size, self.hidden_size, device=inputs.device)
        outputs = []
        for i in range(seq_len):
            input = inputs[i]
            combined = torch.cat((input, hidden), -1)
            forget_gate = torch.sigmoid(self.forget_gate(combined))
            input_gate = torch.sigmoid(self.input_gate(combined))
            cell_gate = torch.tanh(self.cell_gate(combined))
            cell = forget_gate * cell + input_gate * cell_gate
            output_gate = torch.sigmoid(self.output_gate(combined))
            hidden = output_gate * torch.tanh(cell)
            output = self.output_layer(hidden)
            output = self.softmax(output)
            outputs.append(output)
        outputs = torch.stack(outputs, dim=1)  # å°†è¾“å‡ºå¼ é‡çš„ç»´åº¦è°ƒæ•´ä¸º[batch_size, n_seq, output_size]
        return outputs[:, -1, :]

```

ä½¿ç”¨pytorchçš„LSTMæ¨¡å—æ¥ç®€åŒ–ä»£ç ã€‚

```python
import torch
import torch.nn as nn

class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers=2):
        super(LSTM, self).__init__()

        self.hidden_size = hidden_size

        self.lstm = nn.GRU(input_size, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(2 * hidden_size, output_size)

    def forward(self, inputs):
        outputs, h_n = self.lstm(inputs)
        outputs = self.fc(outputs[:, -1, :])
        outputs = torch.log_softmax(outputs, dim=-1)
        return outputs
```

## æ¨¡å‹è®­ç»ƒ

### earlystopå’Œscheduler

è®­ç»ƒè¿‡ç¨‹ä¸­è®¾ç½®äº†`earlystop`å’Œ`scheduler`ã€‚å¯ä»¥æ›´å¥½åœ°ä¼˜åŒ–æ¨¡å‹ï¼Œå‡å°‘æ— ç”¨çš„è®­ç»ƒã€‚

```python
import transformers

def get_scheduler(optim, num_warmup_steps, num_training_steps):
    # num_warmup_stepsæ˜¯warm upé˜¶æ®µçš„æ­¥æ•°
    # num_training_stepsæ˜¯è®­ç»ƒæ€»å…±éœ€è¦çš„æ­¥æ•°
    return transformers.get_linear_schedule_with_warmup(optim, num_warmup_steps, num_training_steps)
```

```python
import numpy as np
import torch
from pathlib import Path


class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""

    def __init__(self, patience=7, verbose=False, delta=0, model_name='default model'):
        """
        Args:
            patience (int): How long to wait after last time validation loss improved.
                            ä¸Šæ¬¡éªŒè¯é›†æŸå¤±å€¼æ”¹å–„åç­‰å¾…å‡ ä¸ªepoch
                            Default: 7
            verbose (bool): If True, prints a message for each validation loss improvement.
                            å¦‚æœæ˜¯Trueï¼Œä¸ºæ¯ä¸ªéªŒè¯é›†æŸå¤±å€¼æ”¹å–„æ‰“å°ä¸€æ¡ä¿¡æ¯
                            Default: False
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
                            ç›‘æµ‹æ•°é‡çš„æœ€å°å˜åŒ–ï¼Œä»¥ç¬¦åˆæ”¹è¿›çš„è¦æ±‚
                            Default: 0
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        root_dir = Path('models_weight')
        root_dir.mkdir(exist_ok=True)
        self.save_path = root_dir / (model_name + '.pkl')

    def __call__(self, val_loss, model):

        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        '''
        Saves model when validation loss decrease.
        éªŒè¯æŸå¤±å‡å°‘æ—¶ä¿å­˜æ¨¡å‹ã€‚
        '''

        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        # torch.save(model.state_dict(), 'checkpoint.pt')     # è¿™é‡Œä¼šå­˜å‚¨è¿„ä»Šæœ€ä¼˜æ¨¡å‹çš„å‚æ•°
        torch.save(model, self.save_path)  # è¿™é‡Œä¼šå­˜å‚¨è¿„ä»Šæœ€ä¼˜çš„æ¨¡å‹
        self.val_loss_min = val_loss
```

### è®­ç»ƒå’ŒéªŒè¯

ä¸€è½®è®­ç»ƒçš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

```python
# import tensorflow as tf
from tqdm import tqdm
import torch
from tensorboardX import SummaryWriter


def train(trainloader, net, criterion, optimizer, epoch, device, train_summary_writer, scheduler):
    net.train()
    with tqdm(trainloader, desc=f'Train epoch {epoch}') as tbar:
        for i, data in enumerate(trainloader):
            inputs, labels = data
            # batch_size, seq_len, input_size = inputs.size()
            nputs, labels = inputs.to(device), labels.to(device)
            # n_categories = trainloader.dataset.n_categories
            optimizer.zero_grad()
            # h0 = torch.randn(1, batch_size, n_categories)
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            scheduler.step()  # è°ƒèŠ‚å­¦ä¹ ç‡
            # accuracy
            accuracy = (labels == torch.argmax(outputs, dim=1)).float().sum() / labels.shape[0]
            # åœ¨tqdmä¸­å±•ç¤ºloss
            tbar.set_postfix(running_loss=loss.item(), acc=f'{100 * accuracy.item():.2f}%')
            # æ›´æ–°è¿›åº¦æ¡
            tbar.update()

            # with train_summary_writer.as_default():
            #     tf.summary.scalar('loss', loss.item(), step=epoch * len(trainloader) + i)
            train_summary_writer.add_scalar('loss', loss.item(), epoch * len(trainloader) + i)
            train_summary_writer.add_scalar('acc', accuracy.item(), epoch * len(trainloader) + i)
```

ä¸€è½®éªŒè¯çš„è¿‡ç¨‹å¦‚ä¸‹ï¼š

```python
# import tensorflow as tf
from tqdm import tqdm
import torch


def evaluate(testloader, net, epoch, device, test_summary_writer):
    with tqdm(testloader, desc=f'Evaluate epoch {epoch}') as tbar:
        # åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•å‡†ç¡®ç‡
        net.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for i, data in enumerate(testloader):
                inputs, labels = data
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = net(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                # åœ¨tqdmä¸­å±•ç¤ºloss

                tbar.set_postfix(eval_acc=f'{100 * correct / total:.2f}%')
                # æ›´æ–°è¿›åº¦æ¡
                tbar.update()
        acc = 100 * correct / total
        test_summary_writer.add_scalar('accuracy', acc, epoch)

    return acc
```

## ç»“æœåˆ†æ

æ¨¡å‹è®­ç»ƒç»“æœçš„ç»˜åˆ¶ç¨‹åºå¦‚ä¸‹ï¼š

å…ˆå°†tensorboardä¸Šçš„ç»“æœä¸Šä¼ åˆ°tensorboard.devï¼Œåœ¨è¯»å–æ•°æ®ï¼Œç»˜åˆ¶losså’Œaccçš„æŠ˜çº¿å›¾ï¼ˆä¸‹é¢çš„é“¾æ¥éƒ½æ˜¯å¯è®¿é—®çš„ï¼‰ã€‚

```python
from utils import plot_loss_acc
# ç»˜åˆ¶losså’Œaccæ›²çº¿
# https://tensorboard.dev/experiment/hYKWk0d6QvaGmzIElxkLJg
model_ls = ['bigru', 'birnn', 'lstm']
experiment_id = "hYKWk0d6QvaGmzIElxkLJg"
group_by = 'bs'
for model in model_ls:
    plot_loss_acc(experiment_id, model, group_by, "compare_batchsize.csv", f"compare_{model}_batchsize.png")

# https://tensorboard.dev/experiment/SWriGlcYRpO3APpWRDDsQA/
model_ls = ['bigru', 'birnn', 'lstm']
experiment_id = "SWriGlcYRpO3APpWRDDsQA"
group_by = "layer_nums"
for model in model_ls:
    plot_loss_acc(experiment_id, model, group_by, "compare_layer_nums.csv", f"compare_{model}_layer_nums.png")

# https://tensorboard.dev/experiment/9HKd2pD2S6ewhbrBgcoGcQ/
model_ls = ['bigru', 'birnn', 'lstm']
experiment_id = "9HKd2pD2S6ewhbrBgcoGcQ"
group_by = "optim"
for model in model_ls:
    plot_loss_acc(experiment_id, model, group_by, "compare_optim.csv", f"compare_{model}_optim.png")

# https://tensorboard.dev/experiment/vYLbQHqzR6qzWhYeCNWIjQ
model_ls = ['bigru', 'birnn', 'lstm']
experiment_id = "vYLbQHqzR6qzWhYeCNWIjQ"
group_by = "optim"
for model in model_ls:
    plot_loss_acc(experiment_id, model, group_by, "compare_optim_bs8_lr0.075.csv",
                  f"compare_{model}_optim_bs8_lr0.075.png")

# https://tensorboard.dev/experiment/gz8hL2OUQ26hRR1FbtVXCg
model_ls = ['gru', 'bigru', 'rnn', 'birnn', 'lstm', 'bilstm']
experiment_id = "gz8hL2OUQ26hRR1FbtVXCg"
group_by = 'model'
plot_loss_acc(experiment_id, 'compare different models', group_by, "compare_model.csv", "compare_model.png")

# https://tensorboard.dev/experiment/ck7LNaMBT2m0z233pZzSmg/
model_ls = ['bigru', 'birnn', 'bilstm']
experiment_id = "ck7LNaMBT2m0z233pZzSmg"
group_by = "lr"
for model in model_ls:
    plot_loss_acc(experiment_id, model, group_by, "compare_lr.csv",
                  f"compare_{model}_lr.png")
```

### æ¯”è¾ƒä¸åŒæ¨¡å‹

è¶…å‚æ•°è®¾ç½®å¦‚ä¸‹ï¼š

`batch_size = 8, learning_rate = 0.075, num_epochs = 30`

æ¨¡å‹æ•ˆæœä¾æ¬¡æ˜¯`BiLSTM>BiGRU>GRU>BiRNN>LSTM>RNN`ã€‚

BiLSTM/BiGRU/LSTM/GRUï¼šè¿™äº›æ¨¡å‹èƒ½å¤Ÿåœ¨å¤„ç†å­—ç¬¦æ—¶åŒæ—¶è€ƒè™‘ä¹‹å‰å’Œä¹‹åçš„ä¿¡æ¯ï¼Œå› æ­¤å…·æœ‰è¾ƒå¥½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿé€šè¿‡é—¨æ§æœºåˆ¶æœ‰æ•ˆåœ°æ•æ‰é•¿åºåˆ—ä¸­çš„ä¿¡æ¯ï¼Œé¿å…äº†æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ç­‰é—®é¢˜ï¼Œå› æ­¤åœ¨å¤„ç†é•¿åºåˆ—æ•°æ®æ—¶ä¹Ÿå…·æœ‰è¾ƒå¥½çš„æ•ˆæœã€‚

BiRNNï¼šç¼ºå°‘é—¨æ§å•å…ƒï¼Œä½†å› ä¸ºä¹Ÿè€ƒè™‘äº†åŒå‘çš„ä¿¡æ¯ï¼Œæ•ˆæœç›¸å¯¹RNNæœ‰æå‡ã€‚

RNNï¼šç»“æ„ç®€å•ï¼Œåœ¨å¤„ç†é•¿åºåˆ—æ•°æ®æ—¶å®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ç­‰é—®é¢˜ï¼Œå› æ­¤æ•ˆæœè¾ƒå·®ã€‚

![model](result/compare_model.png)

### æ¯”è¾ƒä¸åŒä¼˜åŒ–å™¨

å¯¹äºbigruæ¨¡å‹ï¼ŒAdadeltaä¼˜åŒ–å™¨çš„æ•ˆæœæœ€å¥½ï¼Œä½†æ˜¯å„ä¸ªä¼˜åŒ–å™¨çš„åŒºåˆ«éƒ½ä¸æ˜¯å¾ˆå¤§ï¼Œä¸”éƒ½æŒç»­åœ¨è¿›è¡Œæœ‰æ•ˆè®­ç»ƒï¼Œæ²¡æœ‰è¢«æ—©åœæ‰€æˆªæ–­ã€‚

`bs = 8, lr = 0.05`
![bigru](result/compare_bigru_optim.png)

`bs = 8, lr = 0.075`

![bigru](result/compare_bigru_optim_bs8_lr0.075.png)


å¯¹äºbirnnæ¨¡å‹ï¼ŒAdamä¼˜åŒ–å™¨æ•ˆæœæœ€å¥½ï¼Œä¸”RMSpropå’ŒAdagradå‡ºç°äº†æ—©åœï¼Œæ¨¡å‹æ”¶æ•›æ•ˆæœä¹Ÿæ¯”è¾ƒå·®ã€‚

`bs = 8, lr = 0.05`

![birnn](result/compare_birnn_optim.png)

`bs = 8, lr = 0.075`

![birnn](result/compare_birnn_optim_bs8_lr0.075.png)


å¯¹äºlstmæ¨¡å‹ï¼ŒAdagrad(lr=0.05)/Adadelta(lr=0.075)ä¼˜åŒ–å™¨çš„æ•ˆæœæœ€å¥½ï¼Œä½†æ˜¯å„ä¸ªä¼˜åŒ–å™¨çš„åŒºåˆ«éƒ½ä¸æ˜¯å¾ˆå¤§ï¼Œä¸”éƒ½æŒç»­åœ¨è¿›è¡Œæœ‰æ•ˆè®­ç»ƒï¼Œæ²¡æœ‰è¢«æ—©åœæ‰€æˆªæ–­ã€‚

`bs = 8, lr = 0.05`

![lstm](result/compare_lstm_optim.png)

`bs = 8, lr = 0.075`

![lstm](result/compare_lstm_optim_bs8_lr0.075.png)

ä¸åŒçš„ä¼˜åŒ–å™¨åœ¨ä¸åŒæ¨¡å‹ä¸Šçš„æ•ˆæœä¸åŒï¼Œæ”¶æ•›é€Ÿåº¦å’Œæ•ˆæœä¹Ÿå¤§ç›¸å¾„åº­ã€‚å› æ­¤ä¸åŒçš„æ¨¡å‹åº”å½“é€‰æ‹©ä¸åŒä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒã€‚æ”¹å˜å­¦ä¹ ç‡ä¹Ÿä¸€å®šç¨‹åº¦ä¸Šå½±å“äº†ä¼˜åŒ–å™¨å¯¹æ¨¡å‹çš„æ•ˆæœã€‚

### æ¯”è¾ƒä¸åŒbatchsize

éšç€batch_sizeå¢å¤§ï¼Œæ¨¡å‹çš„è®­ç»ƒæ—¶é—´ä¼šå‡å°‘ï¼Œä½†æ¯ä¸ªæ‰¹æ¬¡çš„æ›´æ–°ä¹Ÿä¼šå˜å¾—æ›´åŠ å˜ˆæ‚ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„è¡¨ç°å˜å·®ï¼Œå› ä¸ºæ¨¡å‹æ›´éš¾å­¦ä¹ åˆ°æ•°æ®çš„ç»†èŠ‚ç‰¹å¾ã€‚

æ­¤å¤–ï¼Œå¯¹äºå°æ•°æ®é›†æ¥è¯´ï¼Œä½¿ç”¨å¤§æ‰¹é‡å¤§å°ä¼šå¯¼è‡´æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå› ä¸ºæ¨¡å‹åœ¨æ¯ä¸ªæ‰¹æ¬¡ä¸­éƒ½ä¼šçœ‹åˆ°æ‰€æœ‰çš„æ•°æ®ï¼Œè¿™æ ·å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹å­¦ä¹ åˆ°å™ªå£°è€Œä¸æ˜¯çœŸæ­£çš„æ¨¡å¼ã€‚å› æ­¤ï¼Œé€šå¸¸å»ºè®®åœ¨å°æ•°æ®é›†ä¸Šä½¿ç”¨å°æ‰¹é‡å¤§å°ï¼Œä»¥é¿å…è¿‡åº¦æ‹Ÿåˆå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

![bigru](result/compare_bigru_batchsize.png)

åœ¨RNNæ¨¡å‹ä¸­ï¼Œå‘ç°lossä¸é™åå‡ï¼Œæ¨¡å‹å‡ºç°äº†é€€åŒ–ï¼Œå‡ºç°æ¢¯åº¦çˆ†ç‚¸ï¼Œè€ŒGRUå’ŒLSTMéƒ½æ²¡æœ‰è¿™ä¸ªç°è±¡ã€‚

![birnn](result/compare_birnn_batchsize.png)

![lstm](result/compare_lstm_batchsize.png)

### æ¯”è¾ƒæ¨¡å‹å±‚æ•°

è¶Šæ·±çš„æ¨¡å‹ä¸€èˆ¬æ•ˆæœè¶Šå¥½ï¼Œä¸”æ”¶æ•›é€Ÿåº¦ä¼šæ›´å¿«ã€‚

`batch_size=8, learning_rate=0.1, model=bigru`

![bigru](result/compare_bigru_layer_nums.png)

`batch_size=8, learning_rate=0.1, model=birnn`

![birnn](result/compare_birnn_layer_nums.png)

`batch_size=128, learning_rate=0.05, model=lstm`

å±‚æ•°å¢åŠ åˆ°6æ—¶æ•ˆæœå¼€å§‹ä¸‹é™ã€‚

![lstm](result/compare_lstm_layer_nums.png)

### æ¯”è¾ƒå­¦ä¹ ç‡

BiLSTMæ¨¡å‹è¶…å‚æ•°è®¾ç½®ï¼š`batch_size=8`ï¼Œlearning rateä¸º0.1æ—¶å‡ºç°æ¢¯åº¦çˆ†ç‚¸ã€‚learning rateä¸º0.005/0.05/0.075æ—¶å·®å¼‚ä¸å¤§ã€‚

![compare_bilstm_lr](result/compare_bilstm_lr.png)

BiRNNæ¨¡å‹è¶…å‚æ•°è®¾ç½®ï¼š`batch_size=128`ï¼Œlearning rateè¿‡å¤§æˆ–è¿‡å°éƒ½ä¼šå¯¼è‡´æ¨¡å‹ä¸èƒ½æ­£å¸¸å­¦ä¹ ï¼Œ0.01/0.05/0.075æ˜¯è¾ƒä¸ºæ­£å¸¸ã€‚

![compare_birnn_lr](result/compare_birnn_lr.png)

BiGRUæ¨¡å‹è¶…å‚æ•°è®¾ç½®ï¼š`batch_size=128`ï¼Œå­¦ä¹ ç‡ä¸º0.001/0.005æ—¶å‡ºç°äº†æ¨¡å‹é€€åŒ–ï¼Œè€Œ0.01/0.05çš„å­¦ä¹ ç‡åˆ™è¾ƒä¸ºæ­£å¸¸ã€‚

![compare_bigru_lr](result/compare_bigru_lr.png)

## è¶…å‚æ•°è®¾ç½®çš„å¿ƒå¾—å’Œç»“è®º

### ğŸ‘‘å°batch_sizeå–å¾—äº†å¼‚å¸¸å¥½çš„ç»“æœ

ä»æ•°æ®é›†ç‰¹å¾çš„è§’åº¦ï¼Œè¯¥æ•°æ®é›†è¾ƒå°ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†æŒ‰ç…§8:2åˆ†å‰²åï¼Œè®­ç»ƒé›†åªæœ‰16053æ¡ï¼Œå¯¹äºä¸€ä¸ª18åˆ†ç±»çš„ä»»åŠ¡è€Œè¨€ï¼Œå¹³å‡ä¸€ä¸ªç±»åˆ«åªæœ‰ä¸åˆ°1000æ¡æ•°æ®ã€‚å› æ­¤åœ¨å®éªŒä¸­ä¼šå‘ç°ï¼Œå°½ç®¡batch_sizeçš„å¢å¤§æé«˜äº†æ¨¡å‹è®­ç»ƒçš„é€Ÿåº¦ï¼Œä½†æ˜¯å´æ˜¾è‘—å½±å“äº†æ¨¡å‹æ”¶æ•›é€Ÿåº¦ï¼Œå°½ç®¡ä¸æ–­é™ä½å­¦ä¹ ç‡ï¼Œä¹Ÿæ— æ³•è¾¾åˆ°å°batch_sizeçš„æ°´å¹³ã€‚

ä¾‹å¦‚ï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨BiRNNæ¨¡å‹ï¼Œbatch_sizeåˆ†åˆ«æ˜¯128å’Œ8ï¼Œå­¦ä¹ ç‡åˆ†åˆ«0.05å’Œ0.1çš„ä¸¤ä¸ªè®­ç»ƒç¤ºä¾‹ï¼Œä¼šå‘ç°batch_sizeä¸º8çš„æ¨¡å‹ï¼ˆä¸‹é¢ç§°ä¸ºbs8ï¼‰æ”¶æ•›é€Ÿåº¦è¿œé«˜äºbatch_sizeä¸º128çš„æ¨¡å‹ï¼ˆä¸‹é¢ç§°ä¸ºbs128ï¼‰ã€‚bs128ç»è¿‡120å¤šè½®è®­ç»ƒï¼Œä¹Ÿä»…ä»…å–å¾—äº†56%çš„å‡†ç¡®ç‡ï¼Œè€Œbs8ä»…æœ‰ä¸åˆ°20è½®è®­ç»ƒï¼Œå°±å–å¾—äº†è¿‘65%çš„å‡†ç¡®ç‡ï¼Œå¹¶ä¸”è¿˜æ²¡æœ‰æ˜æ˜¾çš„æ¨¡å‹é€€åŒ–ç°è±¡ã€‚

![bs-128vs8-loss](pics/bs-128vs8.png)

![bs-128vs8-acc](pics/bs-128vs8-acc.png)

### ğŸ‘‘ä¸å¥½çš„å­¦ä¹ ç‡ç›´æ¥å¯¼è‡´äº†æ¨¡å‹ä¸æ”¶æ•›

è¿™æ¬¡å®éªŒè§‚å¯Ÿåˆ°å¾ˆå¤šæ¬¡æ¨¡å‹ä¸æ”¶æ•›çš„ç°è±¡ï¼Œé™¤äº†batch_sizeè®¾ç½®è¿‡å¤§ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªé‡è¦åŸå› å°±æ˜¯å­¦ä¹ ç‡ä¸åˆé€‚ã€‚ä»¥batch_size=8çš„BiGRUæ¨¡å‹ä¸ºä¾‹ï¼Œå­¦ä¹ ç‡åˆ†åˆ«è®¾ç½®ä¸º[0.05, 0.075, 0.1, 0.15, 0.2]ï¼Œ0.2å’Œ0.1çš„æ”¶æ•›æƒ…å†µéƒ½ååˆ†ç³Ÿç³•ï¼Œç›´æ¥å¯¼è‡´å‡†ç¡®ç‡éšè®­ç»ƒè½®æ•°ä¸‹é™ã€‚

![lr-birnn-loss](pics/lr-birnn-loss.png)

![lr-birnn-acc](pics/lr-birnn-acc.png)

### ğŸ‘‘æ¨¡å‹æ·±åº¦æå‡æ¨¡å‹æ•ˆæœ

éšç€å¾ªç¯ç¥ç»ç½‘ç»œçš„å±‚æ•°åŠ æ·±ï¼Œåœ¨ä¸‰ç±»æ¨¡å‹ä¸Šéƒ½èƒ½è§‚å¯Ÿåˆ°æ•ˆæœçš„æå‡ã€‚ä¸è¿‡å› ä¸ºæ¨¡å‹ã€batch_sizeçš„ä¸åŒï¼Œæ•ˆæœçš„æ˜æ˜¾ç¨‹åº¦ä¹Ÿæœ‰ä¸åŒã€‚

ä»¥LSTMå’ŒGRUå’Œä¸ºä¾‹ï¼Œbatch_sizeåˆ†åˆ«ä¸º8å’Œ128ï¼Œå­¦ä¹ ç‡åˆ†åˆ«ä¸º0.05å’Œ0.1ã€‚

å¯¹GRUæ¥è¯´ï¼Œå±‚æ•°è¶Šæ·±ï¼Œæ•ˆæœè¶Šå¥½ã€‚

![layer-nums-gru-loss](pics/layer-nums-bigru-loss.png)

![layer-nums-gru-acc](pics/layer-nums-bigru-acc.png)

å¯¹LSTMæ¥è¯´ï¼Œlayerä¸º4æ—¶ï¼Œæ•ˆæœæœ€å¥½ï¼Œä¸”å·®å¼‚ä¸æ˜¾è‘—ã€‚

![layer-nums-lstm-loss](pics/layer-nums-lstm-loss.png)

![layer-nums-lstmacc](pics/layer-nums-lstm-acc.png)
